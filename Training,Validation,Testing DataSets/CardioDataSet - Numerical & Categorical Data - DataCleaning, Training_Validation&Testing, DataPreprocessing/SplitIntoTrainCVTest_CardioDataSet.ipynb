{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleaning(Numerical & categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "(70000, 13)\n",
      "(67746, 13)\n",
      "   id    age  gender  height  weight  ap_hi  ap_lo cholesterol        gluc  \\\n",
      "0   0  18393    male     168    62.0    110     80  c1_average  g1_average   \n",
      "1   1  20228  female     156    85.0    140     90     c3_high  g1_average   \n",
      "2   2  18857  female     165    64.0    130     70     c3_high  g1_average   \n",
      "3   3  17623    male     169    82.0    150    100  c1_average  g1_average   \n",
      "4   4  17474  female     156    56.0    100     60  c1_average  g1_average   \n",
      "\n",
      "   smoke  alco  active  cardio  \n",
      "0      0     0       1       0  \n",
      "1      0     0       1       1  \n",
      "2      0     0       0       1  \n",
      "3      0     0       1       1  \n",
      "4      0     0       0       0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data=pd.read_csv('cardiouncleaned.csv')\n",
    "\n",
    "y_value_counts = data['cardio'].value_counts() # to count the values in cardio individualy\n",
    "print(y_value_counts.dtype)\n",
    "print(data.shape)\n",
    "\n",
    "data.drop(labels=data[data[\"ap_hi\"]<60].index,axis = 0,inplace = True)#delete rows that have ap_hi value less than 60\n",
    "data.drop(data[data[\"ap_hi\"]>240].index,axis = 0,inplace = True)#delete rows that have ap_hi value grater than 240\n",
    "#data.drop(data[data[\"ap_hi\"]<60 and data[\"ap_hi\"]>240].index,axis = 0,inplace = True)\n",
    "data.drop(data[data[\"ap_lo\"]>180].index,axis = 0,inplace = True)#delete rows that have ap_lo value grater than 180\n",
    "data.drop(data[data[\"ap_lo\"]<40].index,axis = 0,inplace = True)#delete rows that have ap_lo value less than 40\n",
    "#data.drop(data[data[\"ap_lo\"]<40 and data[data[\"ap_lo\"]>180]].index,axis = 0,inplace = True)\n",
    "data.drop(data[data[\"weight\"]<50].index,axis = 0,inplace = True)#delete rows that have weight less than 50 kg\n",
    "data.drop(data[data[\"height\"]<120].index,axis = 0,inplace = True)#delete rows that have height less than 120\n",
    "\n",
    "data['gender']= data['gender'].replace(1,'female') #replace gender value 1 to female\n",
    "data['gender']= data['gender'].replace(2,'male') #replace gender value 2 to male\n",
    "data['cholesterol']= data['cholesterol'].replace(1,'c1_average') #replacing colestrol and all\n",
    "data['cholesterol']= data['cholesterol'].replace(2,'c2_aboveaverage')\n",
    "data['cholesterol']= data['cholesterol'].replace(3,'c3_high')\n",
    "data['gluc']= data['gluc'].replace(1,'g1_average')\n",
    "data['gluc']= data['gluc'].replace(2,'g2_aboveaverage')\n",
    "data['gluc']= data['gluc'].replace(3,'g3_high')\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "\n",
    "data.to_csv (r'cardiocleaned.csv') # saving data in a new file in csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing dataframe into inputs(features) and output(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 0]\n",
      "       Unnamed: 0     id    age  gender  height  weight  ap_hi  ap_lo  \\\n",
      "0               0      0  18393    male     168    62.0    110     80   \n",
      "1               1      1  20228  female     156    85.0    140     90   \n",
      "2               2      2  18857  female     165    64.0    130     70   \n",
      "3               3      3  17623    male     169    82.0    150    100   \n",
      "4               4      4  17474  female     156    56.0    100     60   \n",
      "...           ...    ...    ...     ...     ...     ...    ...    ...   \n",
      "67741       69995  99993  19240    male     168    76.0    120     80   \n",
      "67742       69996  99995  22601  female     158   126.0    140     90   \n",
      "67743       69997  99996  19066    male     183   105.0    180     90   \n",
      "67744       69998  99998  22431  female     163    72.0    135     80   \n",
      "67745       69999  99999  20540  female     170    72.0    120     80   \n",
      "\n",
      "           cholesterol             gluc  smoke  alco  active  \n",
      "0           c1_average       g1_average      0     0       1  \n",
      "1              c3_high       g1_average      0     0       1  \n",
      "2              c3_high       g1_average      0     0       0  \n",
      "3           c1_average       g1_average      0     0       1  \n",
      "4           c1_average       g1_average      0     0       0  \n",
      "...                ...              ...    ...   ...     ...  \n",
      "67741       c1_average       g1_average      1     0       1  \n",
      "67742  c2_aboveaverage  g2_aboveaverage      0     0       1  \n",
      "67743          c3_high       g1_average      0     1       0  \n",
      "67744       c1_average  g2_aboveaverage      0     0       0  \n",
      "67745  c2_aboveaverage       g1_average      0     0       1  \n",
      "\n",
      "[67746 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('cardiocleaned.csv')# reading the cleaned dataset\n",
    "\n",
    "label = data['cardio'].values # output is seperated to a variable called label\n",
    "features = data.drop(['cardio'], axis=1, inplace=False) #Input is seperated to variable data\n",
    "print(label)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into Training,CrossValidation & Testing DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43356, 13)\n",
      "(10840, 13)\n",
      "(13550, 13)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n"
     ]
    }
   ],
   "source": [
    "# split data  into training, validation, testing data\n",
    "from sklearn.model_selection import train_test_split # class to split data \n",
    "\n",
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "#In this context, stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset.\n",
    "inputtrain, inputtest, outputtrain, outputtest = train_test_split(features, label, test_size=0.2, stratify=label)\n",
    "inputtrain, inputcv, outputtrain, outputcv = train_test_split(inputtrain, outputtrain, test_size=0.2, stratify=outputtrain)\n",
    "#60%Train,20%CrossValidation,20%Test DataSets\n",
    "print(inputtrain.shape)\n",
    "print(inputcv.shape)\n",
    "print(inputtest.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing on Training,CV&Testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit() applied only on inputtrain datasets, transform() applied on inputtrain,inputtest,inputcv datasets\n",
    "#fit() & transform() applied on each & every column(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 2)\n",
      "(10840, 2)\n",
      "(13550, 2)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 3)\n",
      "(10840, 3)\n",
      "(13550, 3)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 3)\n",
      "(10840, 3)\n",
      "(13550, 3)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "(43356, 1)\n",
      "(10840, 1)\n",
      "(13550, 1)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# scale age using min max\n",
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(inputtrain['age'].values.reshape(-1,1))\n",
    "inputtrain_age = scale.transform(inputtrain['age'].values.reshape(-1,1))\n",
    "inputcv_age = scale.transform(inputcv['age'].values.reshape(-1,1))\n",
    "inputtest_age = scale.transform(inputtest['age'].values.reshape(-1,1))\n",
    "print(inputtrain_age.shape)\n",
    "print(inputcv_age.shape)\n",
    "print(inputtest_age.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert gender to one hot encoding\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit(inputtrain['gender'].values) \n",
    "\n",
    "inputtrain_gender = vec.transform(inputtrain['gender'].values)\n",
    "inputcv_gender = vec.transform(inputcv['gender'].values)\n",
    "inputtest_gender = vec.transform(inputtest['gender'].values)\n",
    "\n",
    "print(inputtrain_gender.shape)\n",
    "print(inputcv_gender.shape)\n",
    "print(inputtest_gender.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# scale height using min max\n",
    "scale = MinMaxScaler()\n",
    "scale.fit(inputtrain['height'].values.reshape(-1,1)) # reshape because of minmax take column and scale\n",
    "\n",
    "inputtrain_height = scale.transform(inputtrain['height'].values.reshape(-1,1))\n",
    "inputcv_height = scale.transform(inputcv['height'].values.reshape(-1,1))\n",
    "inputtest_height = scale.transform(inputtest['height'].values.reshape(-1,1))\n",
    "print(inputtrain_height.shape)\n",
    "print(inputcv_height.shape)\n",
    "print(inputtest_height.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# scale weight using min max\n",
    "scale = MinMaxScaler()\n",
    "scale.fit(inputtrain['weight'].values.reshape(-1,1)) # reshape because of minmax take column and scale\n",
    "\n",
    "inputtrain_weight = scale.transform(inputtrain['weight'].values.reshape(-1,1))\n",
    "inputcv_weight = scale.transform(inputcv['weight'].values.reshape(-1,1))\n",
    "inputtest_weight = scale.transform(inputtest['weight'].values.reshape(-1,1))\n",
    "print(inputtrain_weight.shape)\n",
    "print(inputcv_weight.shape)\n",
    "print(inputtest_weight.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# scale ap_hi using min max\n",
    "scale = MinMaxScaler()\n",
    "scale.fit(inputtrain['ap_hi'].values.reshape(-1,1)) # reshape because of minmax take column and scale\n",
    "\n",
    "inputtrain_ap_hi = scale.transform(inputtrain['ap_hi'].values.reshape(-1,1))\n",
    "inputcv_ap_hi = scale.transform(inputcv['ap_hi'].values.reshape(-1,1))\n",
    "inputtest_ap_hi = scale.transform(inputtest['ap_hi'].values.reshape(-1,1))\n",
    "print(inputtrain_ap_hi.shape)\n",
    "print(inputcv_ap_hi.shape)\n",
    "print(inputtest_ap_hi.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# scale ap_lo using min max\n",
    "scale = MinMaxScaler()\n",
    "scale.fit(inputtrain['ap_lo'].values.reshape(-1,1)) # reshape because of minmax take column and scale\n",
    "\n",
    "inputtrain_ap_lo = scale.transform(inputtrain['ap_lo'].values.reshape(-1,1))\n",
    "inputcv_ap_lo = scale.transform(inputcv['ap_lo'].values.reshape(-1,1))\n",
    "inputtest_ap_lo = scale.transform(inputtest['ap_lo'].values.reshape(-1,1))\n",
    "print(inputtrain_ap_lo.shape)\n",
    "print(inputcv_ap_lo.shape)\n",
    "print(inputtest_ap_lo.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# convert cholesterol to one hot encoding\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit(inputtrain['cholesterol'].values) \n",
    "\n",
    "inputtrain_cholesterol = vec.transform(inputtrain['cholesterol'].values)\n",
    "inputcv_cholesterol = vec.transform(inputcv['cholesterol'].values)\n",
    "inputtest_cholesterol = vec.transform(inputtest['cholesterol'].values)\n",
    "\n",
    "print(inputtrain_cholesterol.shape)\n",
    "print(inputcv_cholesterol.shape)\n",
    "print(inputtest_cholesterol.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "\n",
    "# convert gluc to one hot encoding\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit(inputtrain['gluc'].values) \n",
    "\n",
    "inputtrain_gluc = vec.transform(inputtrain['gluc'].values)\n",
    "inputcv_gluc = vec.transform(inputcv['gluc'].values)\n",
    "inputtest_gluc = vec.transform(inputtest['gluc'].values)\n",
    "\n",
    "print(inputtrain_gluc.shape)\n",
    "print(inputcv_gluc.shape)\n",
    "print(inputtest_gluc.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# reshape binary feature smoke\n",
    "inputtrain_smoke = inputtrain['smoke'].values.reshape(-1,1)\n",
    "inputcv_smoke = inputcv['smoke'].values.reshape(-1,1)\n",
    "inputtest_smoke = inputtest['smoke'].values.reshape(-1,1)\n",
    "print(inputtrain_smoke.shape)\n",
    "print(inputcv_smoke.shape)\n",
    "print(inputtest_smoke.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "\n",
    "# reshape binary feature alco\n",
    "inputtrain_alco = inputtrain['alco'].values.reshape(-1,1)\n",
    "inputcv_alco = inputcv['alco'].values.reshape(-1,1)\n",
    "inputtest_alco = inputtest['alco'].values.reshape(-1,1)\n",
    "print(inputtrain_alco.shape)\n",
    "print(inputcv_alco.shape)\n",
    "print(inputtest_alco.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "\n",
    "# reshape binary feature active\n",
    "inputtrain_active = inputtrain['active'].values.reshape(-1,1)\n",
    "inputcv_active = inputcv['active'].values.reshape(-1,1)\n",
    "inputtest_active = inputtest['active'].values.reshape(-1,1)\n",
    "print(inputtrain_active.shape)\n",
    "print(inputcv_active.shape)\n",
    "print(inputtest_active.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43356, 16)\n",
      "(10840, 16)\n",
      "(13550, 16)\n",
      "(43356,)\n",
      "(10840,)\n",
      "(13550,)\n",
      "..........................\n",
      "  (0, 0)\t0.6238482384823848\n",
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t0.5641025641025643\n",
      "  (0, 4)\t0.3466666666666667\n",
      "  (0, 5)\t0.4117647058823529\n",
      "  (0, 6)\t0.3571428571428571\n",
      "  (0, 8)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (1, 0)\t0.694463801780875\n",
      "  (1, 2)\t1.0\n",
      "  (1, 3)\t0.641025641025641\n",
      "  (1, 4)\t0.2466666666666667\n",
      "  (1, 5)\t0.3529411764705882\n",
      "  (1, 6)\t0.2857142857142857\n",
      "  (1, 7)\t1.0\n",
      "  (1, 10)\t1.0\n",
      "  (1, 15)\t1.0\n",
      "  (2, 0)\t0.981262098335269\n",
      "  (2, 1)\t1.0\n",
      "  (2, 3)\t0.4487179487179487\n",
      "  (2, 4)\t0.14\n",
      "  (2, 5)\t0.23529411764705888\n",
      "  (2, 6)\t0.2857142857142857\n",
      "  (2, 7)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  :\t:\n",
      "  (43353, 5)\t0.4117647058823529\n",
      "  (43353, 6)\t0.2857142857142857\n",
      "  (43353, 7)\t1.0\n",
      "  (43353, 10)\t1.0\n",
      "  (43353, 15)\t1.0\n",
      "  (43354, 0)\t0.6957801006581493\n",
      "  (43354, 2)\t1.0\n",
      "  (43354, 3)\t0.5641025641025643\n",
      "  (43354, 4)\t0.046666666666666634\n",
      "  (43354, 5)\t0.23529411764705888\n",
      "  (43354, 6)\t0.2142857142857143\n",
      "  (43354, 8)\t1.0\n",
      "  (43354, 10)\t1.0\n",
      "  (43354, 13)\t1.0\n",
      "  (43354, 14)\t1.0\n",
      "  (43354, 15)\t1.0\n",
      "  (43355, 0)\t0.35826558265582664\n",
      "  (43355, 1)\t1.0\n",
      "  (43355, 3)\t0.5256410256410255\n",
      "  (43355, 4)\t0.18000000000000005\n",
      "  (43355, 5)\t0.6470588235294118\n",
      "  (43355, 6)\t0.2142857142857143\n",
      "  (43355, 7)\t1.0\n",
      "  (43355, 10)\t1.0\n",
      "  (43355, 15)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# stack arrays horizontally\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "train = hstack((inputtrain_age,inputtrain_gender,inputtrain_height,inputtrain_weight,inputtrain_ap_hi,inputtrain_ap_lo,inputtrain_cholesterol,inputtrain_gluc,inputtrain_smoke,inputtrain_alco,inputtrain_active)).tocsr()\n",
    "cv = hstack((inputcv_age,inputcv_gender,inputcv_height,inputcv_weight,inputcv_ap_hi,inputcv_ap_lo,inputcv_cholesterol,inputcv_gluc,inputcv_smoke,inputcv_alco,inputcv_active)).tocsr()\n",
    "test = hstack((inputtest_age,inputtest_gender,inputtest_height,inputtest_weight,inputtest_ap_hi,inputtest_ap_lo,inputtest_cholesterol,inputtest_gluc,inputtest_smoke,inputtest_alco,inputtest_active)).tocsr()\n",
    "\n",
    "print(train.shape)\n",
    "print(cv.shape)\n",
    "print(test.shape)\n",
    "print(outputtrain.shape)\n",
    "print(outputcv.shape)\n",
    "print(outputtest.shape)\n",
    "print(\"..........................\")\n",
    "\n",
    "print(train)#sparse Matrix\n",
    "print(train.toarray())# convert sparse matrix to array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputtrain['smoke'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputtrain['smoke'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
